{
  "H1_binary_metrics": {
    "auc_roc": 0.6502937140803755,
    "auc_pr": 0.7817476293813148,
    "brier_score": 0.2627874412376674,
    "log_loss": 4.9867670455352915,
    "_note": "brier_score and log_loss use uncalibrated scores; interpret with caution"
  },
  "H1_auc_ci": {
    "auc": 0.6502937140803755,
    "ci_lower": 0.6336377925132681,
    "ci_upper": 0.6669496356474829,
    "se": 0.008498075321019755
  },
  "sensitivity_2025h2": {
    "full_dataset_n": 5417,
    "full_dataset_auc": 0.6502937140803755,
    "n_2025h2_excluded": 1392,
    "excl_2025h2_n": 4025,
    "excl_2025h2_auc": 0.6751861570938497,
    "auc_delta": 0.024892443013474153
  },
  "sensitivity_stale_threshold": {
    "note": "Primary binary AUC-ROC is invariant to stale threshold choice because merged_at is the ground truth boundary. Threshold variants (5x-median, p75, p90) only affect the rejected/pocket_veto split within non-merged PRs.",
    "primary_auc_invariant": true,
    "primary_auc": 0.6502937140803755,
    "variants": [
      "5x-median",
      "p75",
      "p90"
    ],
    "three_class_note": "Three-class analysis (H1a) is sensitive to threshold choice. Re-run pipeline with each variant to obtain reclassified AUC values."
  },
  "H1a_kruskal_wallis": {
    "h_statistic": 352.41171766445615,
    "p_value": 2.9837870871764294e-77,
    "posthoc": {
      "merged_vs_rejected": {
        "u_statistic": 941967.0,
        "p_value": 2.1951467254485005e-06,
        "adjusted_p": 6.585440176345501e-06
      },
      "merged_vs_pocket_veto": {
        "u_statistic": 2945217.0,
        "p_value": 1.5594736603438256e-77,
        "adjusted_p": 4.678420981031477e-77
      },
      "rejected_vs_pocket_veto": {
        "u_statistic": 293184.0,
        "p_value": 1.8922706966399322e-13,
        "adjusted_p": 5.676812089919797e-13
      }
    }
  },
  "H1a_multinomial_coefs": {
    "classes": [
      "merged",
      "rejected",
      "pocket_veto"
    ],
    "coefficients": [
      [
        0.8786568506061532
      ],
      [
        0.1033168544308256
      ],
      [
        -0.9819737050369797
      ]
    ],
    "intercepts": [
      0.6561750666155856,
      -1.0686414723764166,
      0.4124664057607767
    ]
  },
  "pocket_veto_chi2": {
    "chi2": 67.33100283030427,
    "p_value": 2.3947407526372892e-15,
    "dof": 2,
    "cramers_v": 0.2088933325593565
  },
  "pocket_veto_cochran_armitage": {
    "z_statistic": -0.17674891430001025,
    "p_value": 0.8597056176281248
  },
  "trust_level_odds_ratios": {
    "HIGH_vs_LOW": {
      "odds_ratio": 3.8836372402155757,
      "ci_lower": 3.392271903179044,
      "ci_upper": 4.44617608613704,
      "p_value": 4.907867591598295e-86
    },
    "HIGH_vs_MEDIUM": {
      "odds_ratio": 1.4479021211516723,
      "ci_lower": 1.206013725291198,
      "ci_upper": 1.7383057161553621,
      "p_value": 7.234203643728191e-05
    },
    "MEDIUM_vs_LOW": {
      "odds_ratio": 2.6822512264340777,
      "ci_lower": 2.213465073824143,
      "ci_upper": 3.250320832610844,
      "p_value": 7.743089486349591e-24
    }
  },
  "H2_ablation_corrected": {
    "no_recency": {
      "p_value": 1.4423090818517465e-60,
      "adjusted_p": 8.653854491110479e-60,
      "reject": true,
      "rank": 1
    },
    "no_repo_quality": {
      "p_value": 0.003073748594081444,
      "adjusted_p": 0.015368742970407221,
      "reject": true,
      "rank": 2
    },
    "no_language_match": {
      "p_value": 0.00954549435467008,
      "adjusted_p": 0.03818197741868032,
      "reject": true,
      "rank": 3
    },
    "no_self_penalty": {
      "p_value": 0.32287738964672674,
      "adjusted_p": 0.9686321689401802,
      "reject": false,
      "rank": 4
    },
    "no_language_norm": {
      "p_value": 0.474382961123866,
      "adjusted_p": 0.9686321689401802,
      "reject": false,
      "rank": 5
    },
    "no_diversity_volume": {
      "p_value": 0.5244879492892489,
      "adjusted_p": 0.9686321689401802,
      "reject": false,
      "rank": 6
    }
  },
  "H2_ablation_exploratory": {
    "no_recency_no_quality": {
      "p_value": 1.7265530151203647e-65,
      "adjusted_p": 6.906212060481459e-65,
      "reject": true,
      "rank": 1
    },
    "recursive_quality": {
      "p_value": 0.002007952416429491,
      "adjusted_p": 0.006023857249288473,
      "reject": true,
      "rank": 2
    },
    "no_lang_match_no_lang_norm": {
      "p_value": 0.00812380313278462,
      "adjusted_p": 0.01624760626556924,
      "reject": true,
      "rank": 3
    },
    "no_diversity_no_self_penalty": {
      "p_value": 0.5000543916717124,
      "adjusted_p": 0.5000543916717124,
      "reject": false,
      "rank": 4
    }
  },
  "H2_ablation_raw": {
    "no_diversity_no_self_penalty": {
      "auc": 0.6503680752518326,
      "auc_diff": 7.436117145709353e-05,
      "p_value": 0.5000543916717124
    },
    "no_diversity_volume": {
      "auc": 0.6503630565001033,
      "auc_diff": 6.934241972778032e-05,
      "p_value": 0.5244879492892489
    },
    "no_lang_match_no_lang_norm": {
      "auc": 0.6522041855720255,
      "auc_diff": 0.0019104714916500232,
      "p_value": 0.00812380313278462
    },
    "no_language_match": {
      "auc": 0.652156758368183,
      "auc_diff": 0.0018630442878074804,
      "p_value": 0.00954549435467008
    },
    "no_language_norm": {
      "auc": 0.6503405557631832,
      "auc_diff": 4.684168280766343e-05,
      "p_value": 0.474382961123866
    },
    "no_recency": {
      "auc": 0.5509353113014595,
      "auc_diff": -0.09935840277891606,
      "p_value": 1.4423090818517465e-60
    },
    "no_recency_no_quality": {
      "auc": 0.5463256714838876,
      "auc_diff": -0.10396804259648795,
      "p_value": 1.7265530151203647e-65
    },
    "no_repo_quality": {
      "auc": 0.6475484568844059,
      "auc_diff": -0.0027452571959696304,
      "p_value": 0.003073748594081444
    },
    "no_self_penalty": {
      "auc": 0.6503115306490149,
      "auc_diff": 1.7816568639417163e-05,
      "p_value": 0.32287738964672674
    },
    "recursive_quality": {
      "auc": 0.6474266685091062,
      "auc_diff": -0.0028670455712692666,
      "p_value": 0.002007952416429491
    }
  },
  "H3_account_age_lrt": {
    "lr_statistic": 19.155497231834488,
    "p_value": 1.2048998924317135e-05,
    "df": 1,
    "n_valid": 5417
  },
  "H4_embedding_lrt": {
    "lr_statistic": 35.20045885582408,
    "p_value": 2.9745345474457224e-09,
    "df": 1,
    "n_valid": 1569
  },
  "H5_merge_rate_lrt": {
    "lr_statistic": 51.483257138545014,
    "p_value": 7.221030696948244e-13,
    "df": 1,
    "n_valid": 5129
  },
  "newcomer_cohort": {
    "newcomer": {
      "n": 767,
      "n_merged": 520,
      "n_not_merged": 247,
      "auc_roc": 0.5,
      "auc_ci": {
        "auc": 0.5,
        "ci_lower": 0.5,
        "ci_upper": 0.5,
        "se": 0.0
      },
      "mean_score": 0.0,
      "median_score": 0.0,
      "merge_rate": 0.6779661016949152
    },
    "established": {
      "n": 4650,
      "n_merged": 3354,
      "n_not_merged": 1296,
      "auc_roc": 0.6677662152064606,
      "auc_ci": {
        "auc": 0.6677662152064606,
        "ci_lower": 0.6489588288069039,
        "ci_upper": 0.6865736016060173,
        "se": 0.00959578163063553
      },
      "mean_score": 0.7028523043789472,
      "median_score": 0.8288607790498147,
      "merge_rate": 0.7212903225806452
    }
  },
  "H1a_one_vs_rest_auc": {
    "merged": {
      "auc": 0.6502937140803755,
      "ci_lower": 0.6336377925132681,
      "ci_upper": 0.6669496356474829,
      "se": 0.008498075321019755
    },
    "rejected": {
      "auc": 0.47186410291308617,
      "ci_lower": 0.4428299596057403,
      "ci_upper": 0.500898246220432,
      "se": 0.014813610625686747
    },
    "pocket_veto": {
      "auc": 0.32532131812306714,
      "ci_lower": 0.3071053687389845,
      "ci_upper": 0.3435372675071498,
      "se": 0.009294022506417327
    }
  },
  "confusion_matrix_binary": {
    "threshold": 0.6419284880975784,
    "youdens_j": 0.2755256222332039,
    "matrix": [
      [
        831,
        712
      ],
      [
        1019,
        2855
      ]
    ],
    "labels": [
      "not_merged",
      "merged"
    ]
  },
  "cross_validation": {
    "fold_aucs": [
      0.5933204164207321,
      0.6999891033199849,
      0.7009554824751981,
      0.6226231375502931,
      0.626191280838121
    ],
    "mean_auc": 0.6486158841208658,
    "std_auc": 0.043851375489534196
  },
  "baseline_comparisons": {
    "single_feature_aucs": {
      "author_merge_rate": {
        "label": "Author merge rate",
        "auc": 0.5340792666486923,
        "ci_lower": 0.516328975201404,
        "ci_upper": 0.5518295580959807,
        "n_valid": 5129,
        "vs_ge_delong_z": 9.5683654258244,
        "vs_ge_delong_p": 1.0860915478215953e-21
      },
      "log_account_age_days": {
        "label": "Account age (log)",
        "auc": 0.5655609575912133,
        "ci_lower": 0.5484187577932874,
        "ci_upper": 0.5827031573891391,
        "n_valid": 5417,
        "vs_ge_delong_z": 8.471919693975305,
        "vs_ge_delong_p": 2.4138153153832727e-17
      },
      "log_followers": {
        "label": "Followers (log)",
        "auc": 0.6148973782375549,
        "ci_lower": 0.5983689294233598,
        "ci_upper": 0.6314258270517499,
        "n_valid": 5417,
        "vs_ge_delong_z": 3.7029172411957494,
        "vs_ge_delong_p": 0.00021313442496021605
      },
      "log_public_repos": {
        "label": "Public repos (log)",
        "auc": 0.5416514570607313,
        "ci_lower": 0.524790605832617,
        "ci_upper": 0.5585123082888455,
        "n_valid": 5417,
        "vs_ge_delong_z": 10.970399617134873,
        "vs_ge_delong_p": 5.303746553261598e-28
      },
      "embedding_similarity": {
        "label": "Embedding similarity",
        "auc": 0.41095029518187004,
        "ci_lower": 0.382359731548457,
        "ci_upper": 0.4395408588152831,
        "n_valid": 1569,
        "vs_ge_delong_z": 10.78213812353951,
        "vs_ge_delong_p": 4.1805372722440074e-27
      },
      "total_prs_at_time": {
        "label": "Prior merge count",
        "auc": 0.6037380164755581,
        "ci_lower": 0.587245525090905,
        "ci_upper": 0.6202305078602113,
        "n_valid": 5417,
        "vs_ge_delong_z": 7.143156161247066,
        "vs_ge_delong_p": 9.1211900295957e-13
      }
    },
    "model_A_merge_rate_age": {
      "features": [
        "author_merge_rate",
        "log_account_age_days"
      ],
      "auc": 0.5560817045709143,
      "ci_lower": 0.5383881367290704,
      "ci_upper": 0.5737752724127583,
      "cv_mean": 0.5511579045327409,
      "cv_std": 0.01699165214963883,
      "cv_fold_aucs": [
        0.5838599244956226,
        0.5376099549452907,
        0.5414521134024977,
        0.5413457989912659,
        0.5515217308290282
      ],
      "n_valid": 5129,
      "vs_ge_delong_z": 9.19392707611669,
      "vs_ge_delong_p": 3.787554184710423e-20
    },
    "model_B_merge_rate_age_emb": {
      "features": [
        "author_merge_rate",
        "log_account_age_days",
        "embedding_similarity"
      ],
      "auc": 0.6103050444462458,
      "ci_lower": 0.5810655446467647,
      "ci_upper": 0.6395445442457268,
      "cv_mean": 0.5972558845800825,
      "cv_std": 0.03625139395348465,
      "cv_fold_aucs": [
        0.5820236140433185,
        0.5329819789187351,
        0.6221876326588369,
        0.6315031503150315,
        0.6175830469644903
      ],
      "n_valid": 1495,
      "vs_ge_delong_z": 0.8146929837136458,
      "vs_ge_delong_p": 0.4152480705417747
    },
    "combined_model": {
      "features": [
        "normalized_score",
        "author_merge_rate",
        "log_account_age_days",
        "embedding_similarity"
      ],
      "auc": 0.653877032696843,
      "ci_lower": 0.6253961728611372,
      "ci_upper": 0.6823578925325489,
      "cv_mean": 0.6224794375647792,
      "cv_std": 0.03737019962635774,
      "cv_fold_aucs": [
        0.634334193447494,
        0.6238240961124334,
        0.6030375925663883,
        0.6823582358235823,
        0.5688430698739978
      ],
      "n_valid": 1495,
      "vs_ge_delong_z": -2.221841314227758,
      "vs_ge_delong_p": 0.02629403158129916
    },
    "ge_score": {
      "auc": 0.6502937140803755,
      "ci_lower": 0.6336377925132681,
      "ci_upper": 0.6669496356474829,
      "cv_mean": 0.6486158841208658,
      "cv_std": 0.043851375489534196
    }
  }
}